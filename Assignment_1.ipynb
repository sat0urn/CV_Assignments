{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sat0urn/CV_Assignments/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "G153c6dTHt5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "glRa6TLPGNYW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import pdb\n",
        "\n",
        "# Loading Dataset\n",
        "\n",
        "def load_dataset(data_dir):\n",
        "    classes = os.listdir(data_dir)\n",
        "\n",
        "    images = []\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for class_name in classes:\n",
        "      class_dir = os.path.join(data_dir, class_name)\n",
        "      for image_file in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (128, 128))\n",
        "        images.append(image)\n",
        "        labels.append(class_name)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Agricultural-crops'\n",
        "\n",
        "images, labels = load_dataset(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Softmax Regression Algorithm**"
      ],
      "metadata": {
        "id": "NP60b-gbo3A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax Regression Algorithm\n",
        "class SoftmaxRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=100, regularization='L2', lambda_reg=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.regularization = regularization\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "        self.theta = np.random.rand(num_features, num_classes)\n",
        "\n",
        "        for i in range(self.n_iterations):\n",
        "            scores = X.dot(self.theta)\n",
        "            exp_scores = np.exp(scores)\n",
        "            probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "            delta = probs\n",
        "            delta[range(num_samples), y] -= 1\n",
        "            delta /= num_samples\n",
        "\n",
        "            dtheta = X.T.dot(delta)\n",
        "\n",
        "            if self.regularization == 'L2':\n",
        "                dtheta += self.lambda_reg * self.theta\n",
        "            elif self.regularization == 'L1':\n",
        "                dtheta += self.lambda_reg * np.sign(self.theta)\n",
        "\n",
        "            self.theta -= self.learning_rate * dtheta\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = X.dot(self.theta)\n",
        "        return np.argmax(scores, axis=1)"
      ],
      "metadata": {
        "id": "WypDHNW8o8EN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Algorithm**"
      ],
      "metadata": {
        "id": "mf5rpI1oo_Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Algorithm\n",
        "class SVM:\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=100, regularization='L2', lambda_reg=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.regularization = regularization\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "        self.theta = np.random.rand(num_features, num_classes)\n",
        "\n",
        "        for i in range(self.n_iterations):\n",
        "            scores = X.dot(self.theta)\n",
        "            correct_scores = scores[range(num_samples), y]\n",
        "            margins = np.maximum(0, scores - correct_scores[:, np.newaxis] + 1)\n",
        "            margins[range(num_samples), y] = 0\n",
        "            loss = np.sum(margins) / num_samples\n",
        "\n",
        "            # Compute gradients\n",
        "            binary = margins\n",
        "            binary[margins > 0] = 1\n",
        "            row_sum = np.sum(binary, axis=1)\n",
        "            binary[range(num_samples), y] = -row_sum\n",
        "            dtheta = X.T.dot(binary)\n",
        "\n",
        "            if self.regularization == 'L2':\n",
        "                dtheta += self.lambda_reg * self.theta\n",
        "            elif self.regularization == 'L1':\n",
        "                dtheta += self.lambda_reg * np.sign(self.theta)\n",
        "\n",
        "            self.theta -= self.learning_rate * dtheta\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = X.dot(self.theta)\n",
        "        return np.argmax(scores, axis=1)"
      ],
      "metadata": {
        "id": "Urvh9wBXpBsR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Divide into different sets (train, validation, test)**"
      ],
      "metadata": {
        "id": "_BQyKR3ipFjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide data into train, validation, and test sets\n",
        "def custom_train_val_test_split(X, y, val_size=0.1, test_size=0.1):\n",
        "    num_samples = X.shape[0]\n",
        "    val_size = int(num_samples * val_size)\n",
        "    test_size = int(num_samples * test_size)\n",
        "\n",
        "    indices = np.random.permutation(num_samples)\n",
        "\n",
        "    val_indices = indices[:val_size]\n",
        "    test_indices = indices[val_size:val_size+test_size]\n",
        "    train_indices = indices[val_size+test_size:]\n",
        "\n",
        "    X_val, y_val = X[val_indices], y[val_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = custom_train_val_test_split(images, labels, val_size=0.1, test_size=0.1)"
      ],
      "metadata": {
        "id": "koXwllHmpM1-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split train into train and validation sets for cross-validation**"
      ],
      "metadata": {
        "id": "XwyUhcTypQv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Further split train into train and validation sets for cross-validation\n",
        "def k_fold_split(X, y, k=5):\n",
        "    fold_size = len(X) // k\n",
        "    for i in range(k):\n",
        "        start = i * fold_size\n",
        "        end = (i + 1) * fold_size\n",
        "        X_val = X[start:end]\n",
        "        y_val = y[start:end]\n",
        "        X_train = np.concatenate([X[:start], X[end:]])\n",
        "        y_train = np.concatenate([y[:start], y[end:]])\n",
        "        yield X_train, y_train, X_val, y_val"
      ],
      "metadata": {
        "id": "cBoJp3zzpQ_W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate Accuracy**"
      ],
      "metadata": {
        "id": "-8KHLo05pXu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)"
      ],
      "metadata": {
        "id": "HSDlYZ9FpaZR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialization Models and Accuracy Evaluation**"
      ],
      "metadata": {
        "id": "x9L6aqelpfRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "softmax_model = SoftmaxRegression(learning_rate=0.01, n_iterations=100, regularization='L2', lambda_reg=0.01)\n",
        "svm_model = SVM(learning_rate=0.01, n_iterations=1000, regularization='L2', lambda_reg=0.01)\n",
        "\n",
        "best_accuracy = -1\n",
        "best_model = None\n",
        "\n",
        "for X_train_fold, y_train_fold, X_val_fold, y_val_fold in k_fold_split(X_train, y_train, k=5):\n",
        "    # Train Softmax Regression\n",
        "    softmax_model.fit(X_train_fold, y_train_fold)\n",
        "    softmax_predictions = softmax_model.predict(X_val_fold)\n",
        "    softmax_accuracy = calculate_accuracy(y_val_fold, softmax_predictions)\n",
        "\n",
        "    # Train SVM\n",
        "    svm_model.fit(X_train_fold, y_train_fold)\n",
        "    svm_predictions = svm_model.predict(X_val_fold)\n",
        "    svm_accuracy = calculate_accuracy(y_val_fold, svm_predictions)\n",
        "\n",
        "    if softmax_accuracy > best_accuracy:\n",
        "        best_accuracy = softmax_accuracy\n",
        "        best_model = \"Softmax Regression\"\n",
        "\n",
        "    if svm_accuracy > best_accuracy:\n",
        "        best_accuracy = svm_accuracy\n",
        "        best_model = \"SVM\"\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "if best_model == \"Softmax Regression\":\n",
        "    softmax_model.fit(X_train, y_train)\n",
        "    test_predictions = softmax_model.predict(X_test)\n",
        "elif best_model == \"SVM\":\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    test_predictions = svm_model.predict(X_test)\n",
        "\n",
        "test_accuracy = calculate_accuracy(y_test, test_predictions)\n",
        "\n",
        "print(\"Best Model:\", best_model)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "CG0kQ-nGphrC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}